{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2cPPYqcG9D3"
   },
   "source": [
    "# Bank Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "r8_8lCmkm8sG"
   },
   "source": [
    "### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10931,
     "status": "ok",
     "timestamp": 1549269181134,
     "user": {
      "displayName": "Fazil B. Topal",
      "photoUrl": "https://lh4.googleusercontent.com/-IxiCh57ZfZI/AAAAAAAAAAI/AAAAAAAAAGg/HpcJn-cqYZk/s64/photo.jpg",
      "userId": "06988773581943736669"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "6EQPZa9ACKqV",
    "outputId": "fd9bcbef-e62f-45f9-9a9d-f3d136596981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting memory_profiler\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/fe/1fca7273dd111108f204a686b12a12b6422d405fe4614087aa7d5a66ea87/memory_profiler-0.55.0.tar.gz (40kB)\n",
      "\u001b[K    100% |████████████████████████████████| 40kB 3.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from memory_profiler) (5.4.8)\n",
      "Building wheels for collected packages: memory-profiler\n",
      "  Building wheel for memory-profiler (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f0/ff/63/fdbff3f1e1b76ad4eae491dd5b190902906b093e93eb86dd5a\n",
      "Successfully built memory-profiler\n",
      "Installing collected packages: memory-profiler\n",
      "Successfully installed memory-profiler-0.55.0\n"
     ]
    }
   ],
   "source": [
    "! pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "GYO8FhfADF_c"
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "0dn7lq94nBA8"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "jHJmjJWIHGUA"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.data import Dataset\n",
    "from tensorflow.estimator.inputs import numpy_input_fn, pandas_input_fn\n",
    "from tensorflow.feature_column import numeric_column, categorical_column_with_vocabulary_list, categorical_column_with_identity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "from tensorflow.python.ops import resources\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Pretty Display of Variables\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "ldmE-Nc0nFVO"
   },
   "source": [
    "### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pandas_fn(X, Y, features=None, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \"\"\" Creates a input function that constructs the input function\n",
    "    for the model. You can pass the data after splitting the training and \n",
    "    test data. Function selects features while preparing the data.\n",
    "  \n",
    "    Args:\n",
    "        X: Pandas DataFrame containing the training data.\n",
    "        Y: Pandas Series containing the labels\n",
    "        features: A List containing the names of the features. Default to None\n",
    "        batch_size: Size of each features to fetch. Default value `1`\n",
    "        shuffle: Shuffle the data. Default value `True`\n",
    "        num_epochs: Iteration to fetch the data. `None` for infinity.\n",
    "\n",
    "    Returns:\n",
    "        pandas input function\n",
    "    \"\"\"\n",
    "    if features is not None:\n",
    "        return pandas_input_fn(X[features], Y, batch_size=batch_size, shuffle=shuffle, num_epochs=num_epochs)\n",
    "    else:\n",
    "        return pandas_input_fn(X, Y, batch_size=batch_size, shuffle=shuffle, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def numpy_fn(X, Y, features=None, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \"\"\" Creates a input function that constructs the input function\n",
    "    for the model. You can pass the data after splitting the training and \n",
    "    test data. Function selects features while preparing the data.\n",
    "\n",
    "    Args:\n",
    "        X: Pandas DataFrame containing the training data.\n",
    "        Y: Pandas Series or DataFrame containing the labels\n",
    "        features: A List containing the names of the features. Default to None.\n",
    "        batch_size: Size of each features to fetch. Default value `1`\n",
    "        shuffle: Shuffle the data. Default value `True`\n",
    "        num_epochs: Iteration to fetch the data. `None` for infinity.\n",
    "    \"\"\"\n",
    "  \n",
    "    if features is not None:\n",
    "        return numpy_input_fn(x={key:np.array(value) for key,value in dict(X[features]).items()},\n",
    "                        y=Y.values, batch_size=batch_size, shuffle=shuffle, num_epochs=num_epochs)\n",
    "    else:\n",
    "        return numpy_input_fn(x={key:np.array(value) for key,value in dict(X).items()},\n",
    "                        y=Y.values, batch_size=batch_size, shuffle=shuffle, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_predictions(model, predict_fn):\n",
    "    \"\"\" A Function that produces resuts for the given model.\n",
    "\n",
    "    Args:\n",
    "        model: A model data was train on. tf.estimator object\n",
    "        predict_fn: A function used to predict the output\n",
    "\n",
    "    Returns:\n",
    "        np.array containing prediction results\n",
    "    \"\"\"\n",
    "    predictions = model.predict(input_fn=predict_fn)\n",
    "    return np.array([item['predictions'][0] for item in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def loss2(predictions, y):\n",
    "    \"\"\" Loss function to find the error value of our model\n",
    "  \n",
    "    Args:\n",
    "        predictions: Predicted values\n",
    "        y: Actual values\n",
    "  \n",
    "    Returns:\n",
    "        A Tensor object to containing the error value.\n",
    "  \n",
    "  \"\"\"\n",
    "    return tf.reduce_mean(tf.squared_difference(predictions, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def loss(predictions, y):\n",
    "    \"\"\" Loss function to find the error value of our model. Mean squared error.\n",
    "  \n",
    "    Args:\n",
    "        predictions: Predicted values\n",
    "        y: Actual values\n",
    "  \n",
    "    Returns:\n",
    "        A Tensor object to containing the error value.\n",
    "  \n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(tf.squared_difference(predictions, y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def numeric_to_categorical_features(feature_columns):\n",
    "    \"\"\" Construct TensorFlow categorical columns\n",
    "  \n",
    "    Args:\n",
    "      feature_columns: A dictionary containing category names and \n",
    "      its bucket size as key value pair\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    return set([categorical_column_with_identity(key=k, num_buckets=b) for k, b in feature_columns.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def categorical_features(feature_columns):\n",
    "    \"\"\" Construct TensorFlow categorical columns\n",
    "  \n",
    "    Args:\n",
    "      feature_columns: A dictionary containing category names and \n",
    "      its values as key value pair\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    return set([categorical_column_with_vocabulary_list(key=k, vocabulary_list=v) for k, v in feature_columns.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def numeric_features(feature_columns):\n",
    "    \"\"\"Construct the TensorFlow Feature Columns.\n",
    "\n",
    "    Args:\n",
    "        data(List): The names of the numerical input features to use.\n",
    "    ....\n",
    "    Returns:\n",
    "        A set of feature columns\n",
    "    \"\"\" \n",
    "  \n",
    "    return set([numeric_column(feature) for feature in feature_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def metric_auc(labels, predictions):\n",
    "    return {\n",
    "        'auc_precision_recall': tf.metrics.auc(\n",
    "            labels=labels, predictions=predictions['logistic'], num_thresholds=200,\n",
    "            curve='PR', summation_method='careful_interpolation')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_bank_data(ratio=0.8):\n",
    "    \"\"\" Downloads the banking dataset, preprocess the data and splits it.\n",
    "    Args:\n",
    "        ratio: Split ratio. Default is 0.8\n",
    "    \n",
    "    Returns:\n",
    "        train, test and sample dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    user = \"fazilbtopal\"\n",
    "    key = \"a01ead977f55d872c4deeadb0f173aa1\"\n",
    "\n",
    "    if '.kaggle' not in os.listdir('/root'):\n",
    "        !mkdir ~/.kaggle\n",
    "    !touch /root/.kaggle/kaggle.json\n",
    "    !chmod 666 /root/.kaggle/kaggle.json\n",
    "    with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
    "        f.write('{\"username\":\"%s\",\"key\":\"%s\"}' % (user, key))\n",
    "    !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "    print('Downloading data from web..')\n",
    "    ! kaggle datasets download -d sonujha090/bank-marketing\n",
    "    ! unzip -qq /content/bank-marketing.zip\n",
    "    \n",
    "    print('Reading the dataset..')\n",
    "    # Load the data set.\n",
    "    bank_df = pd.read_csv(\"/content/bank-full.csv\")\n",
    "    bank_sample_df = pd.read_csv(\"/content/bank.csv\")\n",
    "    \n",
    "    print('Converting categories to binary values..')\n",
    "    bank_df[bank_df.y, \"yes\"] = 1\n",
    "    bank_df[bank_df.y, \"no\"] = 0\n",
    "    bank_sample_df[bank_df.y, \"yes\"] = 1\n",
    "    bank_sample_df[bank_df.y, \"no\"] = 0\n",
    "\n",
    "    # Drop NA values\n",
    "    bank_df.dropna(inplace=True)\n",
    "    bank_sample_df.dropna(inplace=True)\n",
    "    \n",
    "    print('Shuffling the data..')\n",
    "    # Shuffle\n",
    "    bank_df = bank_df.reindex(np.random.permutation(bank_df.index))\n",
    "    bank_sample_df = bank_sample_df.reindex(np.random.permutation(bank_sample_df.index))\n",
    "\n",
    "    print('Splitting train & test frames..')\n",
    "    # Split\n",
    "    split_size_head = round(ratio*bank_df.shape[0])\n",
    "    split_size_tail = bank_df.shape[0] - split_size_head\n",
    "    train = bank_df.head(split_size_head)\n",
    "    test = bank_df.tail(split_size_tail)\n",
    "\n",
    "    return train, test, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train, test, sample = process_bank_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "WoQPpKdpoQVy"
   },
   "source": [
    "### Model Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "zOr3KCHSOG8E"
   },
   "source": [
    "#### Estimator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "dfITUfQWJln_"
   },
   "outputs": [],
   "source": [
    "def linear_classifier(labels, funcs, feature_columns, nclasses, learning_rate, steps, quiet=False):\n",
    "    \"\"\" Linear Regression using high level Estimator API\n",
    "  \n",
    "    Args:\n",
    "        labels: A dictionary contains labels as pandas Series for training and testing. \n",
    "                {train: y_train, test: y_test}\n",
    "        funcs: A dictionary contains training/test/predict function to hook up with model.\n",
    "                {train: train_fn, test: test_fn, predict: predict_fn}\n",
    "        feature_columns: Feature columns as list\n",
    "        nclasses: Number of classes in the output column\n",
    "        learning_rate: Learning rate of the model as float\n",
    "        steps: Number of steps required to run the model with parameters as integer\n",
    "        quiet: Selects whether to print results or not.\n",
    "    \n",
    "    \"\"\"\n",
    "    Y_train, Y_test = labels['train'], labels['test']\n",
    "    train_fn, test_fn, predict_fn = funcs['train'], funcs['test'], funcs['predict']\n",
    "    \n",
    "    # Model parameters\n",
    "    model = tf.estimator.LinearClassifier(feature_columns=feature_columns,\n",
    "                                          n_classes=nclasses,\n",
    "                                          optimizer=tf.train.AdamOptimizer(learning_rate))\n",
    "      \n",
    "    # Train the model, starting from the prior state.\n",
    "    model.train(input_fn=train_fn, max_steps=steps)\n",
    "\n",
    "    # Evalute model\n",
    "    eval_result = model.evaluate(input_fn=test_fn)\n",
    "    \n",
    "    if quiet is False:\n",
    "        print(\"Printing Eval Results....\\n\", eval_result)\n",
    "\n",
    "    # Get the loss value\n",
    "    mse = eval_result[\"average_loss\"]\n",
    "\n",
    "    # TODO FROM HERE\n",
    "    # Compute predictions.\n",
    "    predictions = compute_predictions(model, predict_fn)     \n",
    "\n",
    "    # Compute loss.\n",
    "    test_loss = loss(predictions, Y_test)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        test_mse = test_loss.eval()\n",
    "\n",
    "    if quiet is False:\n",
    "        # Print the current loss.\n",
    "        print(\"  Loss for Train: %0.6f\" % (mse**0.5))\n",
    "        print(\"  Loss for Test: %0.6f\" % (test_mse**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "4WfPKCkkEfm2"
   },
   "source": [
    "### Logistic Regression High Level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "6no9vwrdRd9p"
   },
   "source": [
    "**Model Parameters for Logistic Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "bY_XT7tTJvoj"
   },
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "learning_rate = 0.02\n",
    "steps = 200\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "9GPQb6GSGTcA"
   },
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "6zNc6fy7xaCV"
   },
   "outputs": [],
   "source": [
    "feature_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', \n",
    "                   'month', 'poutcome', 'age', 'balance', 'duration']\n",
    "label = \"y\"\n",
    "\n",
    "# Input functions\n",
    "train_input = pandas_fn(train, train[label], features=feature_columns, batch_size=batch_size)\n",
    "test_input = pandas_fn(train, train[label], features=feature_columns, batch_size=1, shuffle=False, num_epochs=1)\n",
    "predict_input = pandas_fn(test, test[label], features=feature_columns, batch_size=1, shuffle=False, num_epochs=1)\n",
    "\n",
    "fns = {'train': train_input, 'test': test_input, 'predict': predict_input}\n",
    "fn_labels = {'train': train[label], 'test': test[label]}\n",
    "\n",
    "categories = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "numerics = ['age', 'balance', 'duration']\n",
    "cats = {c:list(bank_sample_df[c].unique()) for c in categories}\n",
    "features = categorical_features(cats).union(numeric_features(numerics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176269,
     "status": "ok",
     "timestamp": 1549284603701,
     "user": {
      "displayName": "Fazil B. Topal",
      "photoUrl": "https://lh4.googleusercontent.com/-IxiCh57ZfZI/AAAAAAAAAAI/AAAAAAAAAGg/HpcJn-cqYZk/s64/photo.jpg",
      "userId": "06988773581943736669"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "sGEGRZyCdmU7",
    "outputId": "d9b9e414-23c8-4759-cc4e-9cb9b1265c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpjqhw39zy\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "Printing Eval Results....\n",
      " {'accuracy': 0.7853351, 'accuracy_baseline': 0.88343287, 'auc': 0.88751864, 'auc_precision_recall': 0.52794605, 'average_loss': 0.7527573, 'label/mean': 0.116567135, 'loss': 0.7527573, 'precision': 0.3337083, 'prediction/mean': 0.3260792, 'recall': 0.84440225, 'global_step': 200}\n",
      "  Loss for Train: 0.867616\n"
     ]
    }
   ],
   "source": [
    "linear_classifier(fn_labels, fns, feature_columns, nclasses=2, learning_rate=learning_rate, steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 177459,
     "status": "ok",
     "timestamp": 1549284872740,
     "user": {
      "displayName": "Fazil B. Topal",
      "photoUrl": "https://lh4.googleusercontent.com/-IxiCh57ZfZI/AAAAAAAAAAI/AAAAAAAAAGg/HpcJn-cqYZk/s64/photo.jpg",
      "userId": "06988773581943736669"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "pZanPZP2jWEE",
    "outputId": "14274ab6-b6ed-43cc-dfbd-7cb57fc22805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpyxf0canr\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "Printing Eval Results....\n",
      " {'accuracy': 0.8514709, 'accuracy_baseline': 0.88343287, 'auc': 0.8205705, 'auc_precision_recall': 0.3418096, 'average_loss': 0.5692881, 'label/mean': 0.116567135, 'loss': 0.5692881, 'precision': 0.3790795, 'prediction/mean': 0.15986457, 'recall': 0.42979127, 'global_step': 200}\n",
      "  Loss for Train: 0.754512\n",
      "peak memory: 1070.65 MiB, increment: 0.09 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit linear_classifier(fn_labels, fns, feature_columns, nclasses=2, learning_rate=learning_rate, steps=steps, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 348348,
     "status": "ok",
     "timestamp": 1549285047720,
     "user": {
      "displayName": "Fazil B. Topal",
      "photoUrl": "https://lh4.googleusercontent.com/-IxiCh57ZfZI/AAAAAAAAAAI/AAAAAAAAAGg/HpcJn-cqYZk/s64/photo.jpg",
      "userId": "06988773581943736669"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "LpayWEupPavv",
    "outputId": "c68215b5-1d10-4cd4-fe07-abddfe2ea5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpqlam_61v\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "Printing Eval Results....\n",
      " {'accuracy': 0.87900907, 'accuracy_baseline': 0.88343287, 'auc': 0.5886312, 'auc_precision_recall': 0.21392412, 'average_loss': 2.270195, 'label/mean': 0.116567135, 'loss': 2.270195, 'precision': 0.33870968, 'prediction/mean': 0.019721337, 'recall': 0.039848197, 'global_step': 200}\n",
      "  Loss for Train: 1.506717\n",
      "CPU times: user 4min 23s, sys: 50.2 s, total: 5min 13s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%time linear_classifier(fn_labels, fns, feature_columns, nclasses=2, learning_rate=learning_rate, steps=steps, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 522312,
     "status": "ok",
     "timestamp": 1549285222954,
     "user": {
      "displayName": "Fazil B. Topal",
      "photoUrl": "https://lh4.googleusercontent.com/-IxiCh57ZfZI/AAAAAAAAAAI/AAAAAAAAAGg/HpcJn-cqYZk/s64/photo.jpg",
      "userId": "06988773581943736669"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "jgiy8SuQNyGW",
    "outputId": "52ac4d96-402d-4f7a-adc3-cc0a2db687b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpzp1dpd78\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "Printing Eval Results....\n",
      " {'accuracy': 0.8709356, 'accuracy_baseline': 0.88343287, 'auc': 0.88876885, 'auc_precision_recall': 0.5291479, 'average_loss': 0.40094, 'label/mean': 0.116567135, 'loss': 0.40094, 'precision': 0.46169493, 'prediction/mean': 0.19255924, 'recall': 0.64611006, 'global_step': 200}\n",
      "  Loss for Train: 0.633198\n",
      " "
     ]
    }
   ],
   "source": [
    "%prun linear_classifier(fn_labels, fns, feature_columns, nclasses=2, learning_rate=learning_rate, steps=steps, quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "5ppMIdeh6-tN"
   },
   "source": [
    "**Logistic Regression Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "dO-LKX8m7J7Z"
   },
   "source": [
    "**Accuracy**: 0.8709356  \n",
    "**AUC**: 0.88876885  \n",
    "**AUC Precision Recall**: 0.5291479  \n",
    "**Average Loss**: 0.40094  \n",
    "**Loss**: 0.40094  \n",
    "**Precision**: 0.46169493  \n",
    "**Recall**: 0.64611006  \n",
    "\n",
    "\n",
    "**%time**    \n",
    "CPU times: user 4min 23s, sys: 50.2 s, total: 5min 13s  \n",
    "Wall time: 2min 54s\n",
    "\n",
    "**%prun**   \n",
    "9798300 function calls (9429810 primitive calls) in 174.565 seconds\n",
    "\n",
    "**%memit**   \n",
    "peak memory: 1070.65 MiB, increment: 0.09 MiB\n",
    "\n",
    "\n",
    "**Model Parameters**  \n",
    "learning_rate =  0.02\n",
    "steps = 200\n",
    "batch_size = 100"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "r8_8lCmkm8sG",
    "0dn7lq94nBA8",
    "ldmE-Nc0nFVO",
    "DER15wQQnOb5",
    "zOr3KCHSOG8E",
    "6x7WkmNi0T43",
    "Jwej91J_0Tnr",
    "6no9vwrdRd9p",
    "9GPQb6GSGTcA",
    "5ppMIdeh6-tN",
    "vxnnJx0YKMKo",
    "dLmRW0s3KUiJ",
    "_bRBwIEqKvVb"
   ],
   "name": "TF-Classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
